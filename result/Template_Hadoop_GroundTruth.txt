<*>
<*> ATTEMPT_START <*>
<*> Added <*> to list of failed maps <*>
<*> Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context mapreduce <*>
<*> Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context static <*>
<*> Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter) <*>
<*> Adding <*> tokens and <*> secret keys for NM use for launching container <*>
<*> Adding job token for <*> to jobTokenSecretManager <*>
<*> Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server <*>
<*> Address change detected. Old: <*> New: <*>
<*> After Scheduling: <*> CompletedReds:0 <*>
<*> All maps assigned. Ramping up all remaining <*>
<*> Assigned container <*> to <*>
<*> Auth successful for <*> (auth:SIMPLE) <*>
<*> Before Scheduling: <*>
<*> Cannot assign container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <*> Priority: <*> Token: Token { kind: ContainerToken, service: <*> }, ] for a map as either container memory less than required <*> or no pending map tasks - maps.isEmpty=true <*>
<*> Connecting to ResourceManager at <*>
<*> Container complete event for unknown container id <*>
<*> Created MRAppMaster for application <*>
<*> DFSOutputStream ResponseProcessor exception for block <*>
<*> DataStreamer Exception <*>
<*> Default file system <*>
<*> DefaultSpeculator.addSpeculativeAttempt -- we are speculating <*>
<*> Diagnostics report from <*> Container killed by the ApplicationMaster. <*>
<*> Diagnostics report from <*> Error: java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost <*>
<*> Done acknowledgement from <*>
<*> ERROR IN CONTACTING RM. <*>
<*> Emitting job history data to the timeline server is not enabled <*>
<*> Error Recovery for block <*> in pipeline <*> bad datanode <*>
<*> Error writing History Event: <*>
<*> Event Writer setup for JobId: <*> File: <*>
<*> Executing with tokens: <*>
<*> Extract <*> to <*>
<*> Failed to renew lease for <*> for <*> seconds. Will retry shortly ... <*>
<*> Got allocated containers <*>
<*> Http request log for http.requests.mapreduce is not defined <*>
<*> IPC Server Responder: starting <*>
<*> IPC Server listener on <*> starting <*>
<*> Input size for job <*> = <*> Number of splits = <*>
<*> Instantiated MRClientService at <*>
<*> JOB_CREATE <*>
<*> JVM with ID : <*> asked for a task <*>
<*> JVM with ID: <*> given task: <*>
<*> Jetty bound to port <*>
<*> KILLING <*>
<*> Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>
<*> Launching <*>
<*> Logging to <*> via <*>
<*> MRAppMaster launching normal, non-uberized, multi-container job <*>
<*> MRAppMaster metrics system started <*>
<*> Not uberizing <*> because: not enabled; too many maps; too much input; <*>
<*> Num completed Tasks: <*>
<*> Number of reduces for job <*> = <*>
<*> Opening proxy : <*>
<*> OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter <*>
<*> OutputCommitter set in config null <*>
<*> Processing the event EventType: <*> for container <*> taskAttempt <*>
<*> Processing the event EventType: JOB_SETUP <*>
<*> Processing the event EventType: TASK_ABORT <*>
<*> Progress of TaskAttempt <*> is : <*>
<*> Putting shuffle token in serviceData <*>
<*> Recalculating schedule, <*>
<*> Received completed container <*>
<*> Reduce slow start threshold not met. completedMapsForReduceSlowstart <*>
<*> Reduce slow start threshold reached. Scheduling reduces. <*>
<*> Registered webapp guice modules <*>
<*> Registering class <*> for class <*>
<*> Resolved <*> to /default-rack <*>
<*> Retrying connect to server: <*> Already tried <*> time(s); retry policy is <*> MILLISECONDS) <*>
<*> Scheduled snapshot period at <*> second(s). <*>
<*> Scheduling a redundant attempt for task <*>
<*> Shuffle port returned by ContainerManager for <*> : <*>
<*> Size of containertokens_dob is <*>
<*> Slow ReadProcessor read fields took <*> ack: seqno: <*> status: SUCCESS status: ERROR downstreamAckTimeNanos: <*> targets: <*>
<*> Started <*>
<*> Starting Socket Reader <*> for port <*>
<*> Task Transitioned from NEW to SCHEDULED <*>
<*> Task Transitioned from RUNNING to SUCCEEDED <*>
<*> Task Transitioned from SCHEDULED to RUNNING <*>
<*> Task cleanup failed for attempt <*>
<*> Task succeeded with attempt <*>
<*> Task: <*> - exited : java.net.NoRouteToHostException: No Route to Host from <*> to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost <*>
<*> TaskAttempt Transitioned from ASSIGNED to RUNNING <*>
<*> TaskAttempt Transitioned from FAIL_CONTAINER_CLEANUP to FAIL_TASK_CLEANUP <*>
<*> TaskAttempt Transitioned from FAIL_TASK_CLEANUP to FAILED <*>
<*> TaskAttempt Transitioned from NEW to UNASSIGNED <*>
<*> TaskAttempt Transitioned from RUNNING to FAIL_CONTAINER_CLEANUP <*>
<*> TaskAttempt Transitioned from RUNNING to SUCCESS_CONTAINER_CLEANUP <*>
<*> TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED <*>
<*> TaskAttempt Transitioned from UNASSIGNED to ASSIGNED <*>
<*> TaskAttempt: <*> using containerId: <*> on NM: <*>
<*> The job-conf file on the remote FS is <*>
<*> The job-jar file on the remote FS is <*>
<*> Thread <*> threw an Exception. <*>
<*> Transitioned from INITED to SETUP <*>
<*> Transitioned from NEW to INITED <*>
<*> Transitioned from SETUP to RUNNING <*>
<*> Upper limit on the thread pool size is <*>
<*> Using callQueue class java.util.concurrent.LinkedBlockingQueue <*>
<*> Using mapred newApiCommitter. <*>
<*> We launched <*> speculations. Sleeping <*> milliseconds. <*>
<*> Web app /mapreduce started at <*>
<*> adding path spec: <*>
<*> blacklistDisablePercent is <*>
<*> failures on node <*>
<*> getResources() for <*> release= <*>
<*> jetty-6.1.26 <*>
<*> loaded properties from hadoop-metrics2.properties <*>
<*> maxContainerCapability: <*>
<*> maxTaskFailuresPerNode is <*>
<*> nodeBlacklistingEnabled:true <*>
<*> queue: default <*>
<*> yarn.client.max-cached-nodemanagers-proxies : <*>
